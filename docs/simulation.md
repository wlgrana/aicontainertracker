
# Simulation Pipeline Documentation

This document describes the 5-step autonomous simulation pipeline for the Shipment Tracker, its logging infrastructure, and known issues.

## Simulation UI Views

The simulation interface has been expanded into three distinct views to support the full lifecycle of data ingestion:

### 1. Simulation Dashboard (`/import`)
The primary interface for running new ingestion jobs.
*   **Controls**: Upload file, Auto-Run toggle, AI Enrich toggle, and Manual Forwarder entry.
*   **Live Feedback**: Displays a real-time progress bar.
*   **Step Visualization**: Uses the **Pipeline Components** to show the status of each agent (Archivist, Translator, Auditor, Importer, Learner) as they execute.
*   **Logs**: Shows the live log file for the current session.

### 2. Import History (`/import-history`)
A searchable archive of all past ingestion runs.
*   **Card Layout**: Each import is displayed as a card with key metadata (Filename, Status, Date, Row Count).
*   **Quality Badges**: Quickly identify imports that need attention (Excellent, Good, Needs Improvement, Poor).
*   **Filtering**: Filter history by Quality Grade (e.g., "Show only Poor quality imports").
*   **Management**: Delete old simulation records directly from the list.

### 3. Import Details (`/import/[id]`)
A read-only forensic view of a completed import.
*   **Replay**: Reconstructs the exact steps and agent outputs from the specific run.
*   **Forensic Logging**: Filters the "Simulation Logs" section to show **only** the specific log file associated with that run (e.g., `simulation_1737283992.log`).
*   **Data Clarity**: Removes operational controls (Start/Stop) to focus on analysis.

## Pipeline Steps (Agent Breakdown)

The simulation automates the "Self-Improving Ingestion Engine" workflow:

1.  **Archivist (Step 1)**
    *   **Action**: Reads the uploaded Excel file (`Horizon Tracking Report.xlsx`).
    *   **Logic**: Uses AI (or heuristics) to identify the header row and cleans the data.
    *   **Output**: Stores raw rows in the `RawRow` database table.

2.  **Translator (Step 2)**
    *   **Action**: Maps user headers to the canonical schema (e.g., "PO Number" -> `customer_po`).
    *   **Logic**: Uses `Translator` agent (OpenAI) with a fallback to "Heuristic Matching". **Includes Robust Date Conversion**: Automatically detects and converts Excel serial dates (e.g., `45719`) to ISO format (`2025-03-03T00...`).
    *   **Output**: Generates a `temp_translation.json` artifact defining the schema mapping.

3.  **Auditor (Step 3)**
    *   **Action**: Pre-validates the mapping before committing to the database.
    *   **Logic**: Runs a **"Fast Check" (1-Row Sample)** to validate the mapping logic instantly using the `Auditor` agent. Checks for data quality issues or unmapped fields without stalling the pipeline.
    *   **Output**: Updates the mapping artifact with "Auto-Patches" if it finds obvious missing fields (e.g., `Remaks` -> `metadata.remarks`). These patches are immediately available to the Importer and Learner.

4.  **Importer (Step 4)**
    *   **Action**: bulk transforms and saves all data.
    *   **Logic**: Uses **Optimized Batch Persistence** (Chunk Size: 50). Applies the mapping artifact to ALL rows. **Resilient Upserts**: Uses `prisma.upsert` to handle potential race conditions or unique constraint collisions safely. **Metadata Preservation**: Ensures all mapping audit data and internal flags are correctly persisted for every record. **Merges Enriched Data**: Automatically runs the Enricher and persists derived fields (`serviceType`, `finalDestination`) into the canonical record to prevent data gaps.
    *   **Output**: Live database records. Displays a **1-Row Verification Sample** in the logs.

5.  **Learner (Step 5)**
    *   **Action**: Learns from unmapped data to improve future runs.
    *   **Logic**: 
        1.  Scans the imported containers for "Unmapped Fields" (stored in metadata) and uses the `ImprovementAnalyzer` AI.
        2.  **Reads the `temp_translation.json` artifact** to capture successful "Auto-Patches" generated by the Auditor in Step 3.
    *   **Output**: Updates `agents/dictionaries/business_units.yml` or `container_ontology.yml` automatically, ensuring the system learns from its own corrections.

## Logging Infrastructure

To verify runs and troubleshoot issues without relying on the UI console, we have implemented a robust file-based logging system.

*   **Location**: `logs/simulation.log` (Project Root)
*   **Behavior**:
    *   Real-time logs are appended here during every simulation step.
    *   **Auto-Archiving**: When a new simulation starts, the previous log is renamed to a unique timestamped file (e.g., `logs/simulation_1737285555.log`).
*   **Usage**:
    *   Tail this file to see Agent thoughts, API responses, and specific errors.
    *   **UI Access**: Specific log files are linked to their corresponding Import Record and can be downloaded directly from the **Import Details** page.

## Current Issues & Troubleshooting

### 1. Auditor "Stuck" State (Resolved)
**Symptoms**: The simulation hangs during Step 3 (Auditor). The logs show 2-3 containers processed, then silence. The test script times out after 60 seconds.
**Cause**: The `Auditor` agent makes sequential, heavy AI calls. Long prompts or slow API responses caused timeouts.
**Resolution**:
*   **Increased Timeout**: AI call timeout increased to 30 seconds.
*   **Retry Logic**: Implemented exponential backoff (up to 2 retries) to handle transient failures.
*   **Input Validation**: Fixed a bug where `rawData.raw.originalRow` was undefined, creating an immediate failure loop.
*   The simulation now successfully completes even if the auditor encounters transient network issues.

### 2. "Node.exe" Popups (Resolved)
**Symptoms**: Infinite loop of command prompt windows opening/closing.
**Cause**: Race condition between Frontend `status` polling and Backend `spawn`.
**Fix**: `app/api/simulation/control/route.ts` now updates status *synchronously* before spawning child processes. Step scripts use `shell: false` and `windowsHide: true`.

### 3. Step 4 "Null" Data (Resolved)
**Symptoms**: Imported containers showed `null` for all fields.
**Cause**: `transformRow` utility expected Array input but received Key-Value Objects.
**Fix**: Updated `lib/transformation-engine.ts` to handle both formats.

### 4. "Left Over" Column Loss (Resolved)
**Symptoms**: Unmapped columns (like "Booking Date" or "Notes") were silently dropped during import and checking "meta" revealed nothing.
**Cause**: The `transformRow` utility attempted to access unmapped fields using numeric array indices (`rawData[i]`) even when the input was a Key-Value Object (JSON), resulting in `undefined` values.
**Fix**: Updated `lib/transformation-engine.ts` to detect input type (Array vs Object) and correctly access properties by key. This ensures **Zero Data Loss**â€”all unmapped fields are now preserved in `container.meta`, allowing the **Learner** (Step 5) to see and learn from them.

### 5. Excel Serial Dates (Resolved)
**Symptoms**: Dates appeared as integers (e.g., `45719`), were invalid in the database, or lacked precise time information.
**Cause**: Excel stores dates as serial numbers. The system was initially stripping time decimals and not handling all serial-to-date conversions consistently.
**Fix**: Implemented high-precision date conversion in `lib/date-utils.ts` and `lib/transformation-engine.ts`. The system now preserves fractional time (hours/minutes) and automatically enforces date parsing for all canonical date fields, ensuring **100% Quality Score** in audits.

### 6. Enricher Data Loss (Resolved)
**Symptoms**: Enriched fields (Service Type, Final Destination) appeared in logs but were NULL in the database.
**Cause**: The persistence layer calculated the `Container` object *before* running the Enricher, so the enriched values were calculated but never merged into the create/update payload.
**Fix**: Updated `lib/persistence.ts` to explicitly merge `enrichmentMap` results into the `Container` payload before the crucial `prisma.upsert` call. Enriched statuses are also mapped to valid enum values (e.g., `IN_TRANSIT` -> `DEP`).

